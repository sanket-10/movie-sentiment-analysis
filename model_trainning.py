# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np
import pandas as pd
import nltk


df = pd.read_csv("/content/drive/MyDrive/IMDB Dataset.csv")

df

# Lowercasing text

df['review'] = df["review"].str.lower()
df

# remove Html Tags

import re

def remove_html(text):
    pattern = re.compile(r'<.*?>')
    return pattern.sub('', text)

df["review"] = df["review"].apply(remove_html)
df

# remove punctuations

import string

def remove_punctuation(text):
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)

df["review"] = df["review"].apply(remove_punctuation)
df

# Convert numbers into words

# import the inflect library
import inflect
p = inflect.engine()

# convert number into words
def convert_number(text):
    # split string into list of words
    temp_str = text.split()
    # initialise empty list
    new_string = []

    for word in temp_str:
        # if word is a digit, convert the digit
        # to numbers and append into the new_string list
        if word.isdigit():
            temp = p.number_to_words(word)
            new_string.append(temp)

        # append the word as it is
        else:
            new_string.append(word)

    # join the words of new_string to form a string
    temp_str = ' '.join(new_string)
    return temp_str

df["review"] = df["review"].apply(convert_number)

# remove whitespace from text
def remove_whitespace(text):
    return  " ".join(text.split())

df["review"] = df["review"].apply(remove_whitespace)
df['review'][0]

# removing stopwords and word tokenizing and stemming

import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

from nltk.stem.porter import PorterStemmer
from nltk.tokenize import word_tokenize
stemmer = PorterStemmer()

# remove stopwords function
def remove_stopwords(text):
    stop_words = set(stopwords.words("english"))
    word_tokens = word_tokenize(text)
    filtered_text = [word for word in word_tokens if word not in stop_words]
    stems = [stemmer.stem(word) for word in filtered_text]
    return stems

df['filtered_text'] = df['review'].apply(remove_stopwords)
df['filtered_text'][0]

# Label Encoding for positive negative
from sklearn.preprocessing import LabelEncoder
y = df["sentiment"]

lb = LabelEncoder()

y_trans = lb.fit_transform(y)

df["sentiment_trans"] = y_trans
df["sentiment_trans"]

x = df["filtered_text"]
y = y_trans

def prepro(text_list):
  return " ".join(text_list)

x = df["filtered_text"].apply(prepro)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression


text_clf_model = Pipeline([('tfidf',TfidfVectorizer()),
                      ('clf', LogisticRegression()),])

text_clf_model.fit(x,y)

import pickle

# save the iris classification model as a pickle file
model_pkl_file = "movie_sentiment_model1.pkl"

with open(model_pkl_file, 'wb') as file:
    pickle.dump(text_clf_model, file)

